Running on node:
octave
CUDA version:
/var/spool/slurm/d/job123238/slurm_script: line 24: nvcc: command not found
Python version:
Python 3.11.5
Package                           Version
--------------------------------- --------------------
absl-py                           2.0.0
accelerate                        0.30.1
addict                            2.4.0
aiofiles                          23.2.1
aiohttp                           3.9.5
aiosignal                         1.3.1
aliyun-python-sdk-core            2.15.1
aliyun-python-sdk-kms             2.16.3
altair                            5.3.0
annotated-types                   0.6.0
anyio                             4.0.0
argon2-cffi                       23.1.0
argon2-cffi-bindings              21.2.0
arrow                             1.3.0
asttokens                         2.4.1
astunparse                        1.6.3
async-lru                         2.0.4
attrs                             23.1.0
Babel                             2.13.1
backports.functools-lru-cache     1.6.5
beautifulsoup4                    4.12.2
bleach                            6.1.0
blinker                           1.8.2
cachetools                        5.3.2
certifi                           2022.12.7
cffi                              1.16.0
chardet                           5.2.0
charset-normalizer                2.1.1
click                             8.1.7
cloudpickle                       3.0.0
cmake                             3.29.3
colorama                          0.4.6
comm                              0.1.4
contourpy                         1.2.0
crcmod                            1.7
cryptography                      42.0.7
cycler                            0.12.1
DataProperty                      1.0.1
datasets                          2.18.0
debugpy                           1.6.7
decorator                         5.1.1
defusedxml                        0.7.1
dill                              0.3.8
diskcache                         5.6.3
distro                            1.9.0
dnspython                         2.6.1
einops                            0.8.0
email_validator                   2.1.1
exceptiongroup                    1.1.3
executing                         2.0.1
fastapi                           0.111.0
fastapi-cli                       0.0.3
fastjsonschema                    2.18.1
ffmpy                             0.3.2
filelock                          3.14.0
Flask                             3.0.3
flatbuffers                       23.5.26
fonttools                         4.44.0
fqdn                              1.5.1
frozenlist                        1.4.1
fsspec                            2024.2.0
gast                              0.5.4
gevent                            24.2.1
gitdb                             4.0.11
GitPython                         3.1.40
google-auth                       2.23.4
google-auth-oauthlib              1.1.0
google-pasta                      0.2.0
grad-cam                          1.4.8
gradio                            4.31.0
gradio_client                     0.16.2
greenlet                          3.0.3
grpcio                            1.59.2
gunicorn                          22.0.0
h11                               0.14.0
h5py                              3.10.0
httpcore                          1.0.5
httptools                         0.6.1
httpx                             0.27.0
huggingface-hub                   0.23.0
idna                              3.4
importlib-metadata                6.8.0
importlib_resources               6.4.0
interegular                       0.3.3
ipykernel                         6.26.0
ipython                           8.17.2
isoduration                       20.11.0
itsdangerous                      2.2.0
jedi                              0.19.1
Jinja2                            3.1.2
jmespath                          0.10.0
joblib                            1.3.2
json5                             0.9.14
jsonpointer                       2.4
jsonschema                        4.19.2
jsonschema-specifications         2023.7.1
jupyter_client                    8.5.0
jupyter_core                      5.5.0
jupyter-events                    0.8.0
jupyter-lsp                       2.2.0
jupyter_server                    2.9.1
jupyter_server_terminals          0.4.4
jupyterlab                        4.0.8
jupyterlab-pygments               0.2.2
jupyterlab_server                 2.25.0
kaggle                            1.5.16
keras                             2.15.0
kiwisolver                        1.4.5
lark                              1.1.9
libclang                          16.0.6
llvmlite                          0.42.0
lm-format-enforcer                0.9.8
lxml                              5.2.2
Markdown                          3.5.1
markdown-it-py                    3.0.0
MarkupSafe                        2.1.2
matplotlib                        3.8.1
matplotlib-inline                 0.1.6
mbstrdecoder                      1.1.3
mdurl                             0.1.2
mistune                           3.0.2
ml-dtypes                         0.2.0
modelscope                        1.14.0
mpmath                            1.3.0
msgpack                           1.0.8
multidict                         6.0.5
multiprocess                      0.70.16
nbclient                          0.8.0
nbconvert                         7.10.0
nbformat                          5.9.2
nest-asyncio                      1.5.8
networkx                          3.0
ninja                             1.11.1.1
notebook                          7.0.6
notebook_shim                     0.2.3
numba                             0.59.1
numpy                             1.24.1
nvidia-cublas-cu12                12.1.3.1
nvidia-cuda-cupti-cu12            12.1.105
nvidia-cuda-nvrtc-cu12            12.1.105
nvidia-cuda-runtime-cu12          12.1.105
nvidia-cudnn-cu12                 8.9.2.26
nvidia-cufft-cu12                 11.0.2.54
nvidia-curand-cu12                10.3.2.106
nvidia-cusolver-cu12              11.4.5.107
nvidia-cusparse-cu12              12.1.0.106
nvidia-ml-py                      12.550.52
nvidia-nccl-cu12                  2.20.5
nvidia-nvjitlink-cu12             12.4.127
nvidia-nvtx-cu12                  12.1.105
oauthlib                          3.2.2
openai                            1.30.1
opencv-python                     4.8.1.78
opt-einsum                        3.3.0
orjson                            3.10.3
oss2                              2.18.5
outlines                          0.0.34
overrides                         7.4.0
packaging                         23.2
pandas                            2.1.2
pandocfilters                     1.5.0
parso                             0.8.3
pathvalidate                      3.2.0
pexpect                           4.8.0
pickleshare                       0.7.5
Pillow                            10.1.0
pip                               23.3
platformdirs                      3.11.0
portalocker                       2.8.2
prometheus-client                 0.18.0
prometheus-fastapi-instrumentator 7.0.0
prompt-toolkit                    3.0.39
protobuf                          4.23.4
psutil                            5.9.0
ptyprocess                        0.7.0
pure-eval                         0.2.2
py-cpuinfo                        9.0.0
pyarrow                           16.0.0
pyarrow-hotfix                    0.6
pyasn1                            0.5.0
pyasn1-modules                    0.3.0
pycparser                         2.21
pycryptodome                      3.20.0
pydantic                          2.7.1
pydantic_core                     2.18.2
pydub                             0.25.1
Pygments                          2.16.1
pynvml                            11.5.0
pyparsing                         3.1.1
pytablewriter                     1.2.0
python-dateutil                   2.8.2
python-dotenv                     1.0.1
python-json-logger                2.0.7
python-multipart                  0.0.9
python-slugify                    8.0.1
pytz                              2023.3.post1
PyYAML                            6.0.1
pyzmq                             25.1.0
ray                               2.22.0
referencing                       0.30.2
regex                             2024.5.10
requests                          2.31.0
requests-oauthlib                 1.3.1
rfc3339-validator                 0.1.4
rfc3986-validator                 0.1.1
rich                              13.7.1
rouge-chinese                     1.0.3
rpds-py                           0.12.0
rsa                               4.9
ruff                              0.4.4
sacrebleu                         2.4.2
safetensors                       0.4.3
scikit-learn                      1.3.2
scipy                             1.11.3
seaborn                           0.13.0
semantic-version                  2.10.0
Send2Trash                        1.8.2
sentencepiece                     0.2.0
setuptools                        68.0.0
shellingham                       1.5.4
simplejson                        3.19.2
six                               1.16.0
smmap                             5.0.1
sniffio                           1.3.0
sortedcontainers                  2.4.0
soupsieve                         2.5
stack-data                        0.6.2
starlette                         0.37.2
sympy                             1.12
tabledata                         1.3.3
tabulate                          0.9.0
tcolorpy                          0.1.6
tensorboard                       2.15.1
tensorboard-data-server           0.7.2
tensorflow                        2.15.0
tensorflow-estimator              2.15.0
tensorflow-io-gcs-filesystem      0.34.0
termcolor                         2.3.0
terminado                         0.17.1
text-unidecode                    1.3
thop                              0.1.1.post2209072238
threadpoolctl                     3.2.0
tiktoken                          0.6.0
tinycss2                          1.2.1
tokenizers                        0.19.1
tomli                             2.0.1
tomlkit                           0.12.0
toolz                             0.12.1
torch                             2.3.0
torch-cluster                     1.6.3
torch_geometric                   2.4.0
torch-tb-profiler                 0.4.3
torchaudio                        2.1.0+cu118
torchsummary                      1.5.1
torchvision                       0.16.0+cu118
tornado                           6.3.3
tqdm                              4.66.1
traitlets                         5.13.0
transformers                      4.40.2
triton                            2.3.0
ttach                             0.0.3
typepy                            1.3.2
typer                             0.12.3
types-python-dateutil             2.8.19.14
typing_extensions                 4.11.0
tzdata                            2023.3
ujson                             5.9.0
UltraEval                         0.1
ultralytics                       8.0.208
uri-template                      1.3.0
urllib3                           2.2.1
uvicorn                           0.29.0
uvloop                            0.19.0
vllm                              0.4.2
vllm-nccl-cu12                    2.18.1.0.4.0
watchfiles                        0.21.0
wcwidth                           0.2.9
webcolors                         1.13
webencodings                      0.5.1
websocket-client                  1.6.4
websockets                        11.0.3
Werkzeug                          3.0.1
wheel                             0.41.2
wrapt                             1.14.1
xformers                          0.0.26.post1
xxhash                            3.4.1
yapf                              0.40.2
yarl                              1.9.4
zipp                              3.17.0
zope.event                        5.0
zope.interface                    6.3
nvidia_modeset       1310720  0
nvidia_uvm           1536000  4
nvidia              56705024  436 nvidia_uvm,nvidia_modeset
video                  65536  1 nvidia_modeset
drm                   614400  7 drm_kms_helper,drm_vram_helper,ast,nvidia,drm_ttm_helper,ttm
Wed May 15 18:46:25 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:C1:00.0 Off |                    0 |
| N/A   29C    P0              33W / 250W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2.3.0+cu121
True
打印每个传递的参数：
../hf/OpenBMB/MiniCPM-2B-dpo-fp32
1
1
logs/OpenBMB/MiniCPM-2B-dpo-fp32
gsm8k
gen
-1
Available GPUs: 1: 0
The num of datasets is: 61
Datasets for evaluation: gsm8k
The number of selected datasets is 1; the number of selected tasks is 1.
Results have been saved！
[2024-05-15 18:46:34 +0800] [4130009] [INFO] Starting gunicorn 22.0.0
[2024-05-15 18:46:34 +0800] [4130009] [INFO] gunicorn app, gpus_num=1, workers_num=1, per_worker_gpus=1
[2024-05-15 18:46:34 +0800] [4130009] [INFO] Listening at: http://127.0.0.1:5002 (4130009)
[2024-05-15 18:46:34 +0800] [4130009] [INFO] Using worker: sync
[2024-05-15 18:46:34 +0800] [4130010] [INFO] Booting worker with pid: 4130010
[2024-05-15 18:46:34 +0800] [4130010] [INFO] server.age=1, worker.age=1, worker.pid=4130010, gpus=[0]
INFO 05-15 18:46:38 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='../hf/OpenBMB/MiniCPM-2B-dpo-fp32', speculative_config=None, tokenizer='../hf/OpenBMB/MiniCPM-2B-dpo-fp32', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=../hf/OpenBMB/MiniCPM-2B-dpo-fp32)
INFO 05-15 18:46:38 utils.py:660] Found nccl from library /home/ltq/.config/vllm/nccl/cu12/libnccl.so.2.18.1
INFO 05-15 18:46:41 selector.py:81] Cannot use FlashAttention-2 backend because the flash_attn package is not found. Please install it for better performance.
INFO 05-15 18:46:41 selector.py:32] Using XFormers backend.
INFO 05-15 18:47:03 model_runner.py:175] Loading model weights took 5.1034 GB
INFO 05-15 18:47:05 gpu_executor.py:114] # GPU blocks: 5214, # CPU blocks: 728
INFO 05-15 18:47:07 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 05-15 18:47:07 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-15 18:47:12 model_runner.py:1017] Graph capturing finished in 5 secs.
model load finished
127.0.0.1 - - [15/May/2024:18:47:12 +0800] "GET /infer HTTP/1.1" 405 153 "-" "curl/7.88.1"
Service is up!
Postprocessing method: general_torch
Params file: models/model_params/vllm_sample.json
-------final CMD is------
python main.py --model general --model_args url=http://127.0.0.1:5002/infer,concurrency=1 --config_path configs/eval_config.json --output_base_path logs/OpenBMB/MiniCPM-2B-dpo-fp32 --batch_size 32 --postprocess general_torch --params models/model_params/vllm_sample.json --write_out
-------final CMD end------
  0%|          | 0/42 [00:00<?, ?it/s]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:40,  3.23s/it]Processed prompts:   6%|▋         | 2/32 [00:04<01:07,  2.26s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:41,  1.44s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:38,  1.37s/it]Processed prompts:  16%|█▌        | 5/32 [00:07<00:37,  1.39s/it]Processed prompts:  19%|█▉        | 6/32 [00:08<00:31,  1.21s/it]Processed prompts:  22%|██▏       | 7/32 [00:08<00:21,  1.18it/s]Processed prompts:  25%|██▌       | 8/32 [00:09<00:15,  1.60it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:08,  2.51it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:08,  2.39it/s]Processed prompts:  38%|███▊      | 12/32 [00:10<00:07,  2.70it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.17it/s]
127.0.0.1 - - [15/May/2024:18:47:24 +0800] "POST /infer HTTP/1.1" 200 21806 "-" "python-requests/2.31.0"
  2%|▏         | 1/42 [00:10<06:57, 10.19s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:47:24 scheduler.py:648] Input prompt (2051 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:12,  2.43it/s]Processed prompts:   6%|▋         | 2/32 [00:04<01:22,  2.74s/it]Processed prompts:   9%|▉         | 3/32 [00:06<01:03,  2.19s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:38,  1.38s/it]Processed prompts:  16%|█▌        | 5/32 [00:07<00:34,  1.29s/it]Processed prompts:  19%|█▉        | 6/32 [00:08<00:30,  1.17s/it]Processed prompts:  25%|██▌       | 8/32 [00:09<00:19,  1.21it/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:15,  1.52it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:12,  1.76it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.21it/s]
127.0.0.1 - - [15/May/2024:18:47:34 +0800] "POST /infer HTTP/1.1" 200 23069 "-" "python-requests/2.31.0"
  5%|▍         | 2/42 [00:20<06:44, 10.10s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:04,  4.02s/it]Processed prompts:   6%|▋         | 2/32 [00:04<00:53,  1.80s/it]Processed prompts:  12%|█▎        | 4/32 [00:04<00:22,  1.27it/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:31,  1.18s/it]Processed prompts:  19%|█▉        | 6/32 [00:06<00:22,  1.17it/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:17,  1.40it/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:21,  1.13it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:15,  1.53it/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:09,  2.30it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:11,  1.77it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.23it/s]
127.0.0.1 - - [15/May/2024:18:47:44 +0800] "POST /infer HTTP/1.1" 200 21557 "-" "python-requests/2.31.0"
  7%|▋         | 3/42 [00:30<06:32, 10.06s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:51,  3.60s/it]Processed prompts:   6%|▋         | 2/32 [00:03<00:49,  1.64s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:47,  1.64s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:30,  1.09s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:22,  1.18it/s]Processed prompts:  19%|█▉        | 6/32 [00:06<00:17,  1.45it/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:13,  1.88it/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:14,  1.61it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:17,  1.31it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:17,  1.25it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:10,  1.91it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.22it/s]
127.0.0.1 - - [15/May/2024:18:47:54 +0800] "POST /infer HTTP/1.1" 200 22434 "-" "python-requests/2.31.0"
 10%|▉         | 4/42 [00:40<06:23, 10.09s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:47:54 scheduler.py:648] Input prompt (2091 tokens) is too long and exceeds limit of 2048
WARNING 05-15 18:47:55 scheduler.py:648] Input prompt (2060 tokens) is too long and exceeds limit of 2048
Processed prompts:   6%|▋         | 2/32 [00:01<00:15,  1.95it/s]Processed prompts:   9%|▉         | 3/32 [00:04<00:56,  1.93s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:45,  1.63s/it]Processed prompts:  19%|█▉        | 6/32 [00:06<00:24,  1.06it/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:19,  1.23it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:17,  1.35it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:17,  1.27it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:10,  1.87it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.29it/s]
127.0.0.1 - - [15/May/2024:18:48:04 +0800] "POST /infer HTTP/1.1" 200 20756 "-" "python-requests/2.31.0"
 12%|█▏        | 5/42 [00:50<06:09,  9.99s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:48:04 scheduler.py:648] Input prompt (2178 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:16,  1.87it/s]WARNING 05-15 18:48:05 scheduler.py:648] Input prompt (2049 tokens) is too long and exceeds limit of 2048
Processed prompts:   6%|▋         | 2/32 [00:01<00:22,  1.36it/s]Processed prompts:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Processed prompts:  12%|█▎        | 4/32 [00:03<00:24,  1.16it/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:42,  1.58s/it]Processed prompts:  19%|█▉        | 6/32 [00:06<00:29,  1.14s/it]Processed prompts:  22%|██▏       | 7/32 [00:06<00:20,  1.22it/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:11,  1.99it/s]Processed prompts:  31%|███▏      | 10/32 [00:07<00:10,  2.05it/s]Processed prompts:  38%|███▊      | 12/32 [00:08<00:08,  2.45it/s]Processed prompts:  41%|████      | 13/32 [00:08<00:08,  2.24it/s]Processed prompts:  44%|████▍     | 14/32 [00:08<00:07,  2.51it/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:05,  2.98it/s]Processed prompts:  50%|█████     | 16/32 [00:09<00:05,  2.88it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.36it/s]
127.0.0.1 - - [15/May/2024:18:48:13 +0800] "POST /infer HTTP/1.1" 200 19642 "-" "python-requests/2.31.0"
 14%|█▍        | 6/42 [00:59<05:55,  9.86s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:48:13 scheduler.py:648] Input prompt (2228 tokens) is too long and exceeds limit of 2048
WARNING 05-15 18:48:14 scheduler.py:648] Input prompt (2210 tokens) is too long and exceeds limit of 2048
Processed prompts:   6%|▋         | 2/32 [00:00<00:08,  3.61it/s]WARNING 05-15 18:48:14 scheduler.py:648] Input prompt (2391 tokens) is too long and exceeds limit of 2048
Processed prompts:   9%|▉         | 3/32 [00:00<00:08,  3.31it/s]WARNING 05-15 18:48:15 scheduler.py:648] Input prompt (2146 tokens) is too long and exceeds limit of 2048
Processed prompts:  12%|█▎        | 4/32 [00:01<00:14,  1.95it/s]Processed prompts:  16%|█▌        | 5/32 [00:02<00:13,  1.96it/s]Processed prompts:  19%|█▉        | 6/32 [00:03<00:20,  1.28it/s]Processed prompts:  22%|██▏       | 7/32 [00:05<00:26,  1.07s/it]Processed prompts:  25%|██▌       | 8/32 [00:07<00:33,  1.42s/it]Processed prompts:  28%|██▊       | 9/32 [00:08<00:30,  1.33s/it]Processed prompts:  31%|███▏      | 10/32 [00:09<00:26,  1.18s/it]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.39it/s]
127.0.0.1 - - [15/May/2024:18:48:23 +0800] "POST /infer HTTP/1.1" 200 21197 "-" "python-requests/2.31.0"
 17%|█▋        | 7/42 [01:09<05:41,  9.75s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:48:24 scheduler.py:648] Input prompt (2117 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:24,  1.29it/s]Processed prompts:   6%|▋         | 2/32 [00:03<01:05,  2.19s/it]Processed prompts:   9%|▉         | 3/32 [00:04<00:39,  1.35s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:43,  1.54s/it]Processed prompts:  16%|█▌        | 5/32 [00:07<00:37,  1.38s/it]Processed prompts:  19%|█▉        | 6/32 [00:07<00:28,  1.08s/it]Processed prompts:  22%|██▏       | 7/32 [00:09<00:30,  1.23s/it]Processed prompts:  25%|██▌       | 8/32 [00:09<00:21,  1.09it/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:17,  1.35it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:08,  2.40it/s]Processed prompts:  38%|███▊      | 12/32 [00:10<00:06,  2.90it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.14it/s]
127.0.0.1 - - [15/May/2024:18:48:33 +0800] "POST /infer HTTP/1.1" 200 22099 "-" "python-requests/2.31.0"
 19%|█▉        | 8/42 [01:19<05:37,  9.92s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:02<01:22,  2.65s/it]Processed prompts:   6%|▋         | 2/32 [00:04<01:10,  2.35s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:47,  1.64s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:36,  1.29s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:24,  1.12it/s]Processed prompts:  22%|██▏       | 7/32 [00:08<00:21,  1.19it/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:17,  1.40it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:15,  1.39it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.22it/s]
127.0.0.1 - - [15/May/2024:18:48:43 +0800] "POST /infer HTTP/1.1" 200 21456 "-" "python-requests/2.31.0"
 21%|██▏       | 9/42 [01:29<05:28,  9.94s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:53,  3.67s/it]Processed prompts:   6%|▋         | 2/32 [00:04<00:53,  1.77s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:29,  3.09s/it]Processed prompts:  12%|█▎        | 4/32 [00:08<00:53,  1.93s/it]Processed prompts:  16%|█▌        | 5/32 [00:09<00:34,  1.29s/it]Processed prompts:  19%|█▉        | 6/32 [00:10<00:32,  1.24s/it]Processed prompts:  22%|██▏       | 7/32 [00:10<00:22,  1.12it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.08it/s]
127.0.0.1 - - [15/May/2024:18:48:54 +0800] "POST /infer HTTP/1.1" 200 24067 "-" "python-requests/2.31.0"
 24%|██▍       | 10/42 [01:40<05:23, 10.11s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:48:55 scheduler.py:648] Input prompt (2074 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:01<00:33,  1.07s/it]Processed prompts:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Processed prompts:   9%|▉         | 3/32 [00:03<00:34,  1.19s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:44,  1.60s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:33,  1.26s/it]Processed prompts:  19%|█▉        | 6/32 [00:07<00:31,  1.20s/it]Processed prompts:  22%|██▏       | 7/32 [00:08<00:24,  1.01it/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:18,  1.27it/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:21,  1.05it/s]Processed prompts:  31%|███▏      | 10/32 [00:10<00:16,  1.31it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.17it/s]
127.0.0.1 - - [15/May/2024:18:49:04 +0800] "POST /infer HTTP/1.1" 200 22869 "-" "python-requests/2.31.0"
 26%|██▌       | 11/42 [01:50<05:14, 10.14s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:44,  3.38s/it]Processed prompts:   6%|▋         | 2/32 [00:05<01:26,  2.88s/it]Processed prompts:   9%|▉         | 3/32 [00:07<01:05,  2.26s/it]Processed prompts:  12%|█▎        | 4/32 [00:08<00:44,  1.60s/it]Processed prompts:  16%|█▌        | 5/32 [00:08<00:33,  1.25s/it]Processed prompts:  19%|█▉        | 6/32 [00:09<00:25,  1.02it/s]Processed prompts:  22%|██▏       | 7/32 [00:10<00:24,  1.02it/s]Processed prompts:  25%|██▌       | 8/32 [00:10<00:17,  1.41it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.13it/s]
127.0.0.1 - - [15/May/2024:18:49:14 +0800] "POST /infer HTTP/1.1" 200 23407 "-" "python-requests/2.31.0"
 29%|██▊       | 12/42 [02:00<05:05, 10.19s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:02<01:17,  2.51s/it]Processed prompts:   6%|▋         | 2/32 [00:03<00:42,  1.40s/it]Processed prompts:   9%|▉         | 3/32 [00:03<00:29,  1.01s/it]Processed prompts:  12%|█▎        | 4/32 [00:04<00:26,  1.05it/s]Processed prompts:  16%|█▌        | 5/32 [00:05<00:22,  1.23it/s]Processed prompts:  19%|█▉        | 6/32 [00:06<00:25,  1.02it/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:17,  1.41it/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:17,  1.35it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:18,  1.25it/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:10,  1.97it/s]Processed prompts:  41%|████      | 13/32 [00:08<00:06,  3.00it/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:05,  3.35it/s]Processed prompts:  50%|█████     | 16/32 [00:09<00:05,  3.08it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.29it/s]
127.0.0.1 - - [15/May/2024:18:49:24 +0800] "POST /infer HTTP/1.1" 200 19930 "-" "python-requests/2.31.0"
 31%|███       | 13/42 [02:10<04:52, 10.07s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:49:24 scheduler.py:648] Input prompt (2309 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:07,  4.27it/s]Processed prompts:   6%|▋         | 2/32 [00:04<01:11,  2.38s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:55,  1.92s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:37,  1.33s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:30,  1.13s/it]Processed prompts:  19%|█▉        | 6/32 [00:06<00:20,  1.26it/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:10,  2.24it/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:10,  2.30it/s]Processed prompts:  31%|███▏      | 10/32 [00:07<00:07,  2.79it/s]Processed prompts:  38%|███▊      | 12/32 [00:08<00:07,  2.51it/s]Processed prompts:  41%|████      | 13/32 [00:08<00:07,  2.53it/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:08,  2.08it/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:06,  2.59it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.28it/s]
127.0.0.1 - - [15/May/2024:18:49:34 +0800] "POST /infer HTTP/1.1" 200 20642 "-" "python-requests/2.31.0"
 33%|███▎      | 14/42 [02:20<04:40, 10.00s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:49:34 scheduler.py:648] Input prompt (2142 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:05,  5.26it/s]WARNING 05-15 18:49:34 scheduler.py:648] Input prompt (2133 tokens) is too long and exceeds limit of 2048
Processed prompts:   6%|▋         | 2/32 [00:00<00:07,  3.85it/s]WARNING 05-15 18:49:34 scheduler.py:648] Input prompt (2100 tokens) is too long and exceeds limit of 2048
Processed prompts:   9%|▉         | 3/32 [00:00<00:06,  4.24it/s]Processed prompts:  12%|█▎        | 4/32 [00:04<00:50,  1.79s/it]Processed prompts:  16%|█▌        | 5/32 [00:07<00:55,  2.04s/it]Processed prompts:  19%|█▉        | 6/32 [00:07<00:39,  1.51s/it]Processed prompts:  22%|██▏       | 7/32 [00:08<00:26,  1.07s/it]Processed prompts:  25%|██▌       | 8/32 [00:08<00:18,  1.28it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:15,  1.51it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:13,  1.66it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:09,  2.19it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:08,  2.23it/s]Processed prompts:  41%|████      | 13/32 [00:09<00:06,  2.89it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.30it/s]
127.0.0.1 - - [15/May/2024:18:49:44 +0800] "POST /infer HTTP/1.1" 200 20924 "-" "python-requests/2.31.0"
 36%|███▌      | 15/42 [02:30<04:28,  9.94s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:49:45 scheduler.py:648] Input prompt (2177 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:01<00:44,  1.43s/it]Processed prompts:   6%|▋         | 2/32 [00:02<00:43,  1.44s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:59,  2.05s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:39,  1.40s/it]Processed prompts:  19%|█▉        | 6/32 [00:06<00:19,  1.36it/s]Processed prompts:  25%|██▌       | 8/32 [00:06<00:10,  2.27it/s]Processed prompts:  28%|██▊       | 9/32 [00:06<00:10,  2.27it/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:11,  1.85it/s]Processed prompts:  38%|███▊      | 12/32 [00:08<00:11,  1.77it/s]Processed prompts:  41%|████      | 13/32 [00:09<00:11,  1.70it/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:08,  2.15it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.30it/s]
127.0.0.1 - - [15/May/2024:18:49:53 +0800] "POST /infer HTTP/1.1" 200 20702 "-" "python-requests/2.31.0"
 38%|███▊      | 16/42 [02:39<04:17,  9.89s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:46,  3.43s/it]Processed prompts:   6%|▋         | 2/32 [00:04<00:55,  1.87s/it]Processed prompts:   9%|▉         | 3/32 [00:04<00:39,  1.35s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:24,  1.15it/s]Processed prompts:  16%|█▌        | 5/32 [00:05<00:18,  1.45it/s]Processed prompts:  19%|█▉        | 6/32 [00:06<00:17,  1.51it/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:12,  2.06it/s]Processed prompts:  25%|██▌       | 8/32 [00:06<00:10,  2.37it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:18,  1.22it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:18,  1.17it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:18,  1.15it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.21it/s]
127.0.0.1 - - [15/May/2024:18:50:03 +0800] "POST /infer HTTP/1.1" 200 20996 "-" "python-requests/2.31.0"
 40%|████      | 17/42 [02:49<04:08,  9.94s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:30,  4.84s/it]Processed prompts:   6%|▋         | 2/32 [00:05<01:16,  2.54s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:36,  1.30s/it]Processed prompts:  19%|█▉        | 6/32 [00:07<00:19,  1.33it/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:16,  1.49it/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:10,  2.24it/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:11,  1.96it/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:09,  2.13it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:07,  2.52it/s]Processed prompts:  41%|████      | 13/32 [00:09<00:06,  2.79it/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:05,  3.17it/s]Processed prompts:  47%|████▋     | 15/32 [00:10<00:06,  2.75it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.18it/s]
127.0.0.1 - - [15/May/2024:18:50:14 +0800] "POST /infer HTTP/1.1" 200 21502 "-" "python-requests/2.31.0"
 43%|████▎     | 18/42 [03:00<04:00, 10.01s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:50:14 scheduler.py:648] Input prompt (2107 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:17,  1.77it/s]Processed prompts:   6%|▋         | 2/32 [00:07<02:00,  4.02s/it]Processed prompts:   9%|▉         | 3/32 [00:07<01:05,  2.25s/it]Processed prompts:  12%|█▎        | 4/32 [00:07<00:43,  1.57s/it]Processed prompts:  16%|█▌        | 5/32 [00:08<00:31,  1.17s/it]Processed prompts:  19%|█▉        | 6/32 [00:08<00:25,  1.01it/s]Processed prompts:  22%|██▏       | 7/32 [00:09<00:18,  1.35it/s]Processed prompts:  25%|██▌       | 8/32 [00:09<00:12,  1.85it/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:12,  1.91it/s]Processed prompts:  31%|███▏      | 10/32 [00:10<00:11,  1.90it/s]Processed prompts:  38%|███▊      | 12/32 [00:10<00:06,  3.07it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.09it/s]
127.0.0.1 - - [15/May/2024:18:50:24 +0800] "POST /infer HTTP/1.1" 200 22173 "-" "python-requests/2.31.0"
 45%|████▌     | 19/42 [03:10<03:53, 10.13s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:50:24 scheduler.py:648] Input prompt (2054 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:08,  3.54it/s]Processed prompts:   6%|▋         | 2/32 [00:03<00:59,  1.97s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:48,  1.73s/it]Processed prompts:  16%|█▌        | 5/32 [00:07<00:33,  1.25s/it]Processed prompts:  19%|█▉        | 6/32 [00:07<00:27,  1.07s/it]Processed prompts:  22%|██▏       | 7/32 [00:07<00:19,  1.31it/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:13,  1.73it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:10,  2.22it/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:09,  2.27it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:10,  1.95it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:09,  2.04it/s]Processed prompts:  41%|████      | 13/32 [00:09<00:07,  2.67it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.20it/s]
127.0.0.1 - - [15/May/2024:18:50:34 +0800] "POST /infer HTTP/1.1" 200 21096 "-" "python-requests/2.31.0"
 48%|████▊     | 20/42 [03:20<03:42, 10.12s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:50:35 scheduler.py:648] Input prompt (2152 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:22,  1.39it/s]Processed prompts:   6%|▋         | 2/32 [00:03<00:51,  1.72s/it]Processed prompts:   9%|▉         | 3/32 [00:03<00:37,  1.29s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:39,  1.40s/it]Processed prompts:  16%|█▌        | 5/32 [00:05<00:25,  1.07it/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:32,  1.26s/it]Processed prompts:  22%|██▏       | 7/32 [00:08<00:26,  1.06s/it]Processed prompts:  28%|██▊       | 9/32 [00:08<00:16,  1.42it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:16,  1.33it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:09,  2.16it/s]Processed prompts:  41%|████      | 13/32 [00:10<00:07,  2.41it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.18it/s]
127.0.0.1 - - [15/May/2024:18:50:44 +0800] "POST /infer HTTP/1.1" 200 20955 "-" "python-requests/2.31.0"
 50%|█████     | 21/42 [03:30<03:32, 10.12s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:50:45 scheduler.py:648] Input prompt (2250 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:23,  1.30it/s]Processed prompts:   6%|▋         | 2/32 [00:03<00:53,  1.79s/it]Processed prompts:   9%|▉         | 3/32 [00:04<00:41,  1.43s/it]Processed prompts:  12%|█▎        | 4/32 [00:07<00:56,  2.02s/it]Processed prompts:  16%|█▌        | 5/32 [00:07<00:40,  1.49s/it]Processed prompts:  19%|█▉        | 6/32 [00:08<00:29,  1.12s/it]Processed prompts:  22%|██▏       | 7/32 [00:08<00:19,  1.26it/s]Processed prompts:  25%|██▌       | 8/32 [00:09<00:20,  1.20it/s]Processed prompts:  31%|███▏      | 10/32 [00:10<00:14,  1.48it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.12it/s]
127.0.0.1 - - [15/May/2024:18:50:55 +0800] "POST /infer HTTP/1.1" 200 22942 "-" "python-requests/2.31.0"
 52%|█████▏    | 22/42 [03:40<03:23, 10.18s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:50:56 scheduler.py:648] Input prompt (2226 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:01<00:39,  1.26s/it]WARNING 05-15 18:50:56 scheduler.py:648] Input prompt (2094 tokens) is too long and exceeds limit of 2048
Processed prompts:   6%|▋         | 2/32 [00:01<00:20,  1.47it/s]WARNING 05-15 18:50:56 scheduler.py:648] Input prompt (2170 tokens) is too long and exceeds limit of 2048
Processed prompts:   9%|▉         | 3/32 [00:01<00:12,  2.31it/s]Processed prompts:  12%|█▎        | 4/32 [00:02<00:14,  1.99it/s]Processed prompts:  16%|█▌        | 5/32 [00:05<00:38,  1.44s/it]Processed prompts:  19%|█▉        | 6/32 [00:05<00:28,  1.08s/it]Processed prompts:  22%|██▏       | 7/32 [00:07<00:32,  1.30s/it]Processed prompts:  31%|███▏      | 10/32 [00:08<00:14,  1.51it/s]Processed prompts:  38%|███▊      | 12/32 [00:08<00:10,  1.98it/s]Processed prompts:  41%|████      | 13/32 [00:09<00:10,  1.75it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.38it/s]
127.0.0.1 - - [15/May/2024:18:51:04 +0800] "POST /infer HTTP/1.1" 200 20399 "-" "python-requests/2.31.0"
 55%|█████▍    | 23/42 [03:50<03:09, 10.00s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:51:06 scheduler.py:648] Input prompt (2239 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.67s/it]Processed prompts:   6%|▋         | 2/32 [00:02<00:32,  1.09s/it]Processed prompts:   9%|▉         | 3/32 [00:03<00:29,  1.02s/it]Processed prompts:  12%|█▎        | 4/32 [00:04<00:26,  1.05it/s]Processed prompts:  16%|█▌        | 5/32 [00:05<00:32,  1.20s/it]Processed prompts:  22%|██▏       | 7/32 [00:06<00:16,  1.50it/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:21,  1.12it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:22,  1.04it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:21,  1.01it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.25it/s]
127.0.0.1 - - [15/May/2024:18:51:14 +0800] "POST /infer HTTP/1.1" 200 21204 "-" "python-requests/2.31.0"
 57%|█████▋    | 24/42 [04:00<02:59,  9.97s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:51:15 scheduler.py:648] Input prompt (2059 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:17,  1.81it/s]Processed prompts:   6%|▋         | 2/32 [00:03<00:59,  1.98s/it]Processed prompts:   9%|▉         | 3/32 [00:04<00:39,  1.36s/it]Processed prompts:  12%|█▎        | 4/32 [00:04<00:32,  1.14s/it]Processed prompts:  19%|█▉        | 6/32 [00:05<00:15,  1.68it/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:17,  1.47it/s]Processed prompts:  25%|██▌       | 8/32 [00:06<00:15,  1.54it/s]Processed prompts:  31%|███▏      | 10/32 [00:07<00:12,  1.83it/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:12,  1.74it/s]Processed prompts:  41%|████      | 13/32 [00:08<00:09,  2.02it/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:10,  1.77it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.29it/s]
127.0.0.1 - - [15/May/2024:18:51:24 +0800] "POST /infer HTTP/1.1" 200 19590 "-" "python-requests/2.31.0"
 60%|█████▉    | 25/42 [04:10<02:48,  9.92s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:41,  3.27s/it]Processed prompts:   6%|▋         | 2/32 [00:07<02:00,  4.01s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:11,  2.47s/it]Processed prompts:  12%|█▎        | 4/32 [00:08<00:45,  1.62s/it]Processed prompts:  16%|█▌        | 5/32 [00:09<00:32,  1.20s/it]Processed prompts:  22%|██▏       | 7/32 [00:10<00:22,  1.09it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.05it/s]
127.0.0.1 - - [15/May/2024:18:51:34 +0800] "POST /infer HTTP/1.1" 200 23349 "-" "python-requests/2.31.0"
 62%|██████▏   | 26/42 [04:20<02:41, 10.12s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:51:34 scheduler.py:648] Input prompt (2124 tokens) is too long and exceeds limit of 2048
WARNING 05-15 18:51:35 scheduler.py:648] Input prompt (2178 tokens) is too long and exceeds limit of 2048
Processed prompts:   6%|▋         | 2/32 [00:00<00:12,  2.33it/s]WARNING 05-15 18:51:35 scheduler.py:648] Input prompt (2408 tokens) is too long and exceeds limit of 2048
WARNING 05-15 18:51:36 scheduler.py:648] Input prompt (2084 tokens) is too long and exceeds limit of 2048
Processed prompts:  12%|█▎        | 4/32 [00:01<00:11,  2.34it/s]WARNING 05-15 18:51:36 scheduler.py:648] Input prompt (2262 tokens) is too long and exceeds limit of 2048
Processed prompts:  19%|█▉        | 6/32 [00:03<00:17,  1.50it/s]Processed prompts:  22%|██▏       | 7/32 [00:03<00:13,  1.81it/s]Processed prompts:  25%|██▌       | 8/32 [00:04<00:14,  1.65it/s]Processed prompts:  28%|██▊       | 9/32 [00:06<00:20,  1.11it/s]Processed prompts:  34%|███▍      | 11/32 [00:06<00:12,  1.70it/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:12,  1.54it/s]Processed prompts:  41%|████      | 13/32 [00:07<00:11,  1.69it/s]Processed prompts:  44%|████▍     | 14/32 [00:08<00:09,  1.96it/s]Processed prompts:  47%|████▋     | 15/32 [00:08<00:07,  2.23it/s]Processed prompts:  50%|█████     | 16/32 [00:08<00:05,  2.77it/s]Processed prompts:  53%|█████▎    | 17/32 [00:09<00:05,  2.61it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.54it/s]
127.0.0.1 - - [15/May/2024:18:51:44 +0800] "POST /infer HTTP/1.1" 200 18448 "-" "python-requests/2.31.0"
 64%|██████▍   | 27/42 [04:29<02:27,  9.82s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:51:44 scheduler.py:648] Input prompt (2072 tokens) is too long and exceeds limit of 2048
WARNING 05-15 18:51:45 scheduler.py:648] Input prompt (2057 tokens) is too long and exceeds limit of 2048
Processed prompts:   6%|▋         | 2/32 [00:01<00:27,  1.08it/s]Processed prompts:   9%|▉         | 3/32 [00:04<00:51,  1.77s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:46,  1.67s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:33,  1.25s/it]Processed prompts:  19%|█▉        | 6/32 [00:07<00:27,  1.06s/it]Processed prompts:  22%|██▏       | 7/32 [00:07<00:19,  1.28it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:13,  1.69it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:14,  1.48it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:13,  1.60it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.24it/s]
127.0.0.1 - - [15/May/2024:18:51:53 +0800] "POST /infer HTTP/1.1" 200 21822 "-" "python-requests/2.31.0"
 67%|██████▋   | 28/42 [04:39<02:18,  9.86s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:36,  3.11s/it]Processed prompts:   6%|▋         | 2/32 [00:03<00:49,  1.63s/it]Processed prompts:   9%|▉         | 3/32 [00:04<00:31,  1.07s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:33,  1.21s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:28,  1.05s/it]Processed prompts:  19%|█▉        | 6/32 [00:07<00:29,  1.12s/it]Processed prompts:  25%|██▌       | 8/32 [00:08<00:16,  1.47it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:15,  1.53it/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:11,  1.95it/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:08,  2.36it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:12,  1.64it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.20it/s]
127.0.0.1 - - [15/May/2024:18:52:04 +0800] "POST /infer HTTP/1.1" 200 22175 "-" "python-requests/2.31.0"
 69%|██████▉   | 29/42 [04:50<02:09,  9.92s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:52:05 scheduler.py:648] Input prompt (2164 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:01<00:53,  1.74s/it]Processed prompts:   6%|▋         | 2/32 [00:02<00:31,  1.06s/it]Processed prompts:   9%|▉         | 3/32 [00:03<00:35,  1.21s/it]Processed prompts:  12%|█▎        | 4/32 [00:04<00:28,  1.02s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:33,  1.25s/it]Processed prompts:  19%|█▉        | 6/32 [00:06<00:27,  1.08s/it]Processed prompts:  22%|██▏       | 7/32 [00:08<00:32,  1.29s/it]Processed prompts:  25%|██▌       | 8/32 [00:08<00:22,  1.08it/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:21,  1.09it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:11,  1.77it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.21it/s]
127.0.0.1 - - [15/May/2024:18:52:14 +0800] "POST /infer HTTP/1.1" 200 20886 "-" "python-requests/2.31.0"
 71%|███████▏  | 30/42 [05:00<01:59,  9.97s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:11,  4.24s/it]Processed prompts:   6%|▋         | 2/32 [00:06<01:34,  3.16s/it]Processed prompts:   9%|▉         | 3/32 [00:07<01:02,  2.15s/it]Processed prompts:  22%|██▏       | 7/32 [00:08<00:21,  1.19it/s]Processed prompts:  25%|██▌       | 8/32 [00:09<00:20,  1.20it/s]Processed prompts:  28%|██▊       | 9/32 [00:10<00:16,  1.39it/s]Processed prompts:  34%|███▍      | 11/32 [00:10<00:10,  2.06it/s]Processed prompts:  38%|███▊      | 12/32 [00:10<00:08,  2.28it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.02it/s]
127.0.0.1 - - [15/May/2024:18:52:24 +0800] "POST /infer HTTP/1.1" 200 22987 "-" "python-requests/2.31.0"
 74%|███████▍  | 31/42 [05:10<01:51, 10.18s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:02<01:16,  2.47s/it]Processed prompts:   6%|▋         | 2/32 [00:03<00:41,  1.38s/it]Processed prompts:   9%|▉         | 3/32 [00:03<00:23,  1.25it/s]Processed prompts:  12%|█▎        | 4/32 [00:04<00:30,  1.10s/it]Processed prompts:  16%|█▌        | 5/32 [00:05<00:29,  1.10s/it]Processed prompts:  19%|█▉        | 6/32 [00:06<00:23,  1.09it/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:16,  1.53it/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:12,  1.91it/s]Processed prompts:  31%|███▏      | 10/32 [00:07<00:09,  2.37it/s]Processed prompts:  34%|███▍      | 11/32 [00:07<00:08,  2.35it/s]Processed prompts:  38%|███▊      | 12/32 [00:08<00:08,  2.48it/s]Processed prompts:  41%|████      | 13/32 [00:09<00:10,  1.83it/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:09,  1.83it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.31it/s]
127.0.0.1 - - [15/May/2024:18:52:34 +0800] "POST /infer HTTP/1.1" 200 19683 "-" "python-requests/2.31.0"
 76%|███████▌  | 32/42 [05:20<01:40, 10.05s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:36,  5.06s/it]Processed prompts:   6%|▋         | 2/32 [00:05<01:12,  2.43s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:41,  1.42s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:24,  1.10it/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:27,  1.07s/it]Processed prompts:  25%|██▌       | 8/32 [00:08<00:16,  1.49it/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:15,  1.50it/s]Processed prompts:  31%|███▏      | 10/32 [00:10<00:15,  1.38it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.11it/s]
127.0.0.1 - - [15/May/2024:18:52:44 +0800] "POST /infer HTTP/1.1" 200 22192 "-" "python-requests/2.31.0"
 79%|███████▊  | 33/42 [05:30<01:31, 10.14s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:52:45 scheduler.py:648] Input prompt (2067 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:27,  1.13it/s]Processed prompts:   6%|▋         | 2/32 [00:02<00:35,  1.20s/it]Processed prompts:   9%|▉         | 3/32 [00:03<00:38,  1.32s/it]Processed prompts:  12%|█▎        | 4/32 [00:03<00:24,  1.12it/s]Processed prompts:  16%|█▌        | 5/32 [00:04<00:19,  1.35it/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:38,  1.48s/it]Processed prompts:  22%|██▏       | 7/32 [00:08<00:30,  1.23s/it]Processed prompts:  25%|██▌       | 8/32 [00:08<00:21,  1.10it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:15,  1.49it/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:12,  1.80it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:12,  1.62it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:10,  1.91it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.25it/s]
127.0.0.1 - - [15/May/2024:18:52:54 +0800] "POST /infer HTTP/1.1" 200 20641 "-" "python-requests/2.31.0"
 81%|████████  | 34/42 [05:40<01:20, 10.08s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:46,  3.44s/it]Processed prompts:   6%|▋         | 2/32 [00:03<00:48,  1.61s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:46,  1.60s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:29,  1.04s/it]Processed prompts:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Processed prompts:  19%|█▉        | 6/32 [00:09<00:39,  1.54s/it]Processed prompts:  25%|██▌       | 8/32 [00:10<00:21,  1.10it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.19it/s]
127.0.0.1 - - [15/May/2024:18:53:05 +0800] "POST /infer HTTP/1.1" 200 22880 "-" "python-requests/2.31.0"
 83%|████████▎ | 35/42 [05:51<01:10, 10.12s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:53:06 scheduler.py:648] Input prompt (2139 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:01<00:54,  1.77s/it]Processed prompts:   6%|▋         | 2/32 [00:03<01:00,  2.01s/it]Processed prompts:   9%|▉         | 3/32 [00:04<00:44,  1.53s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:28,  1.02s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:35,  1.32s/it]Processed prompts:  19%|█▉        | 6/32 [00:07<00:23,  1.09it/s]Processed prompts:  22%|██▏       | 7/32 [00:08<00:23,  1.09it/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:18,  1.31it/s]Processed prompts:  31%|███▏      | 10/32 [00:10<00:16,  1.31it/s]Processed prompts:  34%|███▍      | 11/32 [00:10<00:13,  1.57it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.11it/s]
127.0.0.1 - - [15/May/2024:18:53:15 +0800] "POST /infer HTTP/1.1" 200 21663 "-" "python-requests/2.31.0"
 86%|████████▌ | 36/42 [06:01<01:01, 10.19s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:53:15 scheduler.py:648] Input prompt (2179 tokens) is too long and exceeds limit of 2048
Processed prompts:   6%|▋         | 2/32 [00:06<01:36,  3.21s/it]Processed prompts:   9%|▉         | 3/32 [00:06<00:58,  2.02s/it]Processed prompts:  12%|█▎        | 4/32 [00:07<00:38,  1.38s/it]Processed prompts:  16%|█▌        | 5/32 [00:07<00:28,  1.06s/it]Processed prompts:  19%|█▉        | 6/32 [00:09<00:31,  1.22s/it]Processed prompts:  28%|██▊       | 9/32 [00:09<00:13,  1.64it/s]Processed prompts:  31%|███▏      | 10/32 [00:10<00:12,  1.71it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.16it/s]
127.0.0.1 - - [15/May/2024:18:53:25 +0800] "POST /infer HTTP/1.1" 200 22702 "-" "python-requests/2.31.0"
 88%|████████▊ | 37/42 [06:11<00:50, 10.19s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:53:27 scheduler.py:648] Input prompt (2049 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:01<00:56,  1.82s/it]Processed prompts:   6%|▋         | 2/32 [00:03<00:46,  1.56s/it]Processed prompts:   9%|▉         | 3/32 [00:06<01:05,  2.26s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:28,  1.07s/it]Processed prompts:  19%|█▉        | 6/32 [00:07<00:23,  1.10it/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:18,  1.34it/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:13,  1.79it/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:09,  2.21it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:11,  1.86it/s]Processed prompts:  41%|████      | 13/32 [00:09<00:06,  2.74it/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:04,  3.40it/s]Processed prompts:  53%|█████▎    | 17/32 [00:09<00:03,  3.91it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.21it/s]
127.0.0.1 - - [15/May/2024:18:53:35 +0800] "POST /infer HTTP/1.1" 200 20670 "-" "python-requests/2.31.0"
 90%|█████████ | 38/42 [06:21<00:40, 10.16s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:53:35 scheduler.py:648] Input prompt (2095 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:00<00:03,  7.91it/s]WARNING 05-15 18:53:37 scheduler.py:648] Input prompt (2078 tokens) is too long and exceeds limit of 2048
Processed prompts:   6%|▋         | 2/32 [00:01<00:28,  1.06it/s]WARNING 05-15 18:53:37 scheduler.py:648] Input prompt (2354 tokens) is too long and exceeds limit of 2048
Processed prompts:   9%|▉         | 3/32 [00:01<00:19,  1.48it/s]Processed prompts:  12%|█▎        | 4/32 [00:05<00:51,  1.86s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:44,  1.66s/it]Processed prompts:  19%|█▉        | 6/32 [00:07<00:30,  1.17s/it]Processed prompts:  22%|██▏       | 7/32 [00:07<00:21,  1.18it/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:16,  1.43it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:14,  1.62it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:15,  1.39it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:12,  1.72it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:10,  1.93it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.27it/s]
127.0.0.1 - - [15/May/2024:18:53:45 +0800] "POST /infer HTTP/1.1" 200 21449 "-" "python-requests/2.31.0"
 93%|█████████▎| 39/42 [06:31<00:30, 10.11s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]WARNING 05-15 18:53:47 scheduler.py:648] Input prompt (2074 tokens) is too long and exceeds limit of 2048
Processed prompts:   3%|▎         | 1/32 [00:01<00:51,  1.67s/it]Processed prompts:   6%|▋         | 2/32 [00:03<00:49,  1.66s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:59,  2.06s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:41,  1.47s/it]Processed prompts:  16%|█▌        | 5/32 [00:07<00:37,  1.37s/it]Processed prompts:  22%|██▏       | 7/32 [00:07<00:19,  1.31it/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:15,  1.52it/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:13,  1.72it/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:11,  1.86it/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:09,  2.31it/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:06,  2.89it/s]Processed prompts:  41%|████      | 13/32 [00:09<00:05,  3.31it/s]Processed prompts:  44%|████▍     | 14/32 [00:10<00:06,  2.60it/s]Processed prompts: 100%|██████████| 32/32 [00:10<00:00,  3.11it/s]
127.0.0.1 - - [15/May/2024:18:53:56 +0800] "POST /infer HTTP/1.1" 200 22003 "-" "python-requests/2.31.0"
 95%|█████████▌| 40/42 [06:41<00:20, 10.19s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:42,  3.32s/it]Processed prompts:   6%|▋         | 2/32 [00:05<01:11,  2.37s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:44,  1.54s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:29,  1.04s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:23,  1.17it/s]Processed prompts:  19%|█▉        | 6/32 [00:06<00:18,  1.42it/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:14,  1.69it/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:13,  1.79it/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:09,  2.33it/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:09,  2.19it/s]Processed prompts:  41%|████      | 13/32 [00:08<00:05,  3.18it/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:06,  2.75it/s]Processed prompts: 100%|██████████| 32/32 [00:09<00:00,  3.24it/s]
127.0.0.1 - - [15/May/2024:18:54:05 +0800] "POST /infer HTTP/1.1" 200 20775 "-" "python-requests/2.31.0"
 98%|█████████▊| 41/42 [06:51<00:10, 10.12s/it]Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s]Processed prompts:  14%|█▍        | 1/7 [00:03<00:20,  3.37s/it]Processed prompts:  29%|██▊       | 2/7 [00:04<00:10,  2.08s/it]Processed prompts: 100%|██████████| 7/7 [00:04<00:00,  1.54it/s]
127.0.0.1 - - [15/May/2024:18:54:10 +0800] "POST /infer HTTP/1.1" 200 5169 "-" "python-requests/2.31.0"
100%|██████████| 42/42 [06:56<00:00,  8.45s/it]100%|██████████| 42/42 [06:56<00:00,  9.92s/it]
<<gsm8k_gsm8k_gen>> Gathered metrics are: defaultdict(<class 'list'>, {'accuracy': [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]})
<<gsm8k_gsm8k_gen>> Final Metric is: {'accuracy': 0.38817285822592873}
For detailed output of the model, see logs/OpenBMB/MiniCPM-2B-dpo-fp32/2024-05-15_18-47-13/gsm8k_gsm8k_gen/instance.jsonl

Here are the results for each task:
|     Task      | Metric |Value |
|---------------|--------|-----:|
|gsm8k_gsm8k_gen|accuracy|0.3882|


Here are the results for each dataset:
|Dataset| Metric |Value |
|-------|--------|-----:|
|gsm8k  |accuracy|0.3882|

Path 'logs/OpenBMB/MiniCPM-2B-dpo-fp32/2024-05-15_18-47-13' already exists.

The results of all tasks have been saved to the logs/OpenBMB/MiniCPM-2B-dpo-fp32/2024-05-15_18-47-13/_all_results.json

Running time: 417.18408274650574 seconds
Running time: 417.18408274650574 seconds, the whole time: 417.18408823013306 seconds
[2024-05-15 18:54:11 +0800] [4130009] [INFO] Handling signal: term
[2024-05-15 18:54:11 +0800] [4130010] [INFO] Worker exiting (pid: 4130010)
[2024-05-15 18:54:14 +0800] [4130009] [WARNING] worker exit. pid=4130010, gpus=[0]
[2024-05-15 18:54:14 +0800] [4130009] [INFO] Shutting down: Master
