Running on node:
ja3
CUDA version:
/var/spool/slurm/d/job123506/slurm_script: line 24: nvcc: command not found
Python version:
Python 3.11.5
nvidia_uvm           1372160  0
nvidia_drm             73728  0
nvidia_modeset       1249280  1 nvidia_drm
video                  65536  1 nvidia_modeset
drm_kms_helper        204800  5 drm_vram_helper,ast,nvidia_drm
nvidia              56537088  17 nvidia_uvm,nvidia_modeset
drm                   614400  8 drm_kms_helper,drm_vram_helper,ast,nvidia,drm_ttm_helper,nvidia_drm,ttm
Thu May 16 18:49:11 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:01:00.0 Off |                    0 |
| N/A   35C    P0    27W / 250W |      0MiB / 16384MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
2.3.0+cu121
True
打印每个传递的参数：
../hf/OpenBMB/MiniCPM-2B-dpo-fp32
1
1
logs/OpenBMB/MiniCPM-2B-dpo-fp32
gsm8k
gen
5
Available GPUs: 1: 0
The num of datasets is: 61
Datasets for evaluation: gsm8k
The number of selected datasets is 1; the number of selected tasks is 1.
Results have been saved！
[2024-05-16 18:49:15 +0800] [150134] [INFO] Starting gunicorn 22.0.0
[2024-05-16 18:49:15 +0800] [150134] [INFO] gunicorn app, gpus_num=1, workers_num=1, per_worker_gpus=1
[2024-05-16 18:49:15 +0800] [150134] [INFO] Listening at: http://127.0.0.1:5002 (150134)
[2024-05-16 18:49:15 +0800] [150134] [INFO] Using worker: sync
[2024-05-16 18:49:15 +0800] [150135] [INFO] Booting worker with pid: 150135
[2024-05-16 18:49:15 +0800] [150135] [INFO] server.age=1, worker.age=1, worker.pid=150135, gpus=[0]
INFO 05-16 18:49:18 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='../hf/OpenBMB/MiniCPM-2B-dpo-fp32', speculative_config=None, tokenizer='../hf/OpenBMB/MiniCPM-2B-dpo-fp32', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=../hf/OpenBMB/MiniCPM-2B-dpo-fp32)
INFO 05-16 18:49:18 utils.py:660] Found nccl from library /home/ltq/.config/vllm/nccl/cu12/libnccl.so.2.18.1
INFO 05-16 18:49:20 selector.py:69] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.
INFO 05-16 18:49:20 selector.py:32] Using XFormers backend.
INFO 05-16 18:49:26 model_runner.py:175] Loading model weights took 5.1034 GB
INFO 05-16 18:49:27 gpu_executor.py:114] # GPU blocks: 1348, # CPU blocks: 728
INFO 05-16 18:49:29 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 05-16 18:49:29 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 18:49:34 model_runner.py:1017] Graph capturing finished in 5 secs.
model load finished
127.0.0.1 - - [16/May/2024:18:49:45 +0800] "GET /infer HTTP/1.1" 405 153 "-" "curl/7.88.1"
Service is up!
Postprocessing method: general_torch
Params file: models/model_params/vllm_sample.json
-------final CMD is------
python main.py --model general --model_args url=http://127.0.0.1:5002/infer,concurrency=1 --config_path configs/eval_config.json --output_base_path logs/OpenBMB/MiniCPM-2B-dpo-fp32 --batch_size 64 --postprocess general_torch --params models/model_params/vllm_sample.json --write_out --num_fewshot 5
-------final CMD end------
  0%|          | 0/21 [00:00<?, ?it/s]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:55,  1.83s/it]Processed prompts:   9%|▉         | 6/64 [00:02<00:15,  3.76it/s]Processed prompts:  23%|██▎       | 15/64 [00:02<00:05,  8.86it/s]Processed prompts:  58%|█████▊    | 37/64 [00:03<00:01, 15.71it/s]Processed prompts:  61%|██████    | 39/64 [00:03<00:01, 15.36it/s]Processed prompts:  64%|██████▍   | 41/64 [00:03<00:01, 14.74it/s]Processed prompts:  70%|███████   | 45/64 [00:03<00:01, 16.48it/s]Processed prompts:  77%|███████▋  | 49/64 [00:04<00:00, 19.30it/s]Processed prompts:  81%|████████▏ | 52/64 [00:04<00:00, 18.70it/s]Processed prompts:  86%|████████▌ | 55/64 [00:04<00:00, 13.31it/s]Processed prompts:  89%|████████▉ | 57/64 [00:04<00:00, 12.13it/s]Processed prompts:  92%|█████████▏| 59/64 [00:05<00:00,  9.43it/s]Processed prompts:  95%|█████████▌| 61/64 [00:06<00:00,  5.31it/s]Processed prompts:  97%|█████████▋| 62/64 [00:07<00:00,  2.82it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.41it/s]
127.0.0.1 - - [16/May/2024:18:49:54 +0800] "POST /infer HTTP/1.1" 200 10897 "-" "python-requests/2.31.0"
  5%|▍         | 1/21 [00:07<02:34,  7.72s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:53,  1.80s/it]Processed prompts:   6%|▋         | 4/64 [00:01<00:22,  2.63it/s]Processed prompts:  34%|███▍      | 22/64 [00:02<00:03, 13.49it/s]Processed prompts:  81%|████████▏ | 52/64 [00:03<00:00, 24.72it/s]Processed prompts:  86%|████████▌ | 55/64 [00:03<00:00, 23.31it/s]Processed prompts:  91%|█████████ | 58/64 [00:04<00:00, 15.41it/s]Processed prompts:  94%|█████████▍| 60/64 [00:04<00:00, 15.65it/s]Processed prompts:  97%|█████████▋| 62/64 [00:05<00:00,  7.73it/s]Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  6.55it/s]Processed prompts: 100%|██████████| 64/64 [00:06<00:00, 10.60it/s]
127.0.0.1 - - [16/May/2024:18:50:00 +0800] "POST /infer HTTP/1.1" 200 5422 "-" "python-requests/2.31.0"
 10%|▉         | 2/21 [00:13<02:08,  6.76s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:53,  1.80s/it]Processed prompts:  23%|██▎       | 15/64 [00:02<00:06,  7.62it/s]Processed prompts:  48%|████▊     | 31/64 [00:02<00:01, 18.02it/s]Processed prompts:  75%|███████▌  | 48/64 [00:03<00:00, 19.27it/s]Processed prompts:  84%|████████▍ | 54/64 [00:03<00:00, 20.01it/s]Processed prompts:  92%|█████████▏| 59/64 [00:04<00:00, 17.48it/s]Processed prompts:  98%|█████████▊| 63/64 [00:07<00:00,  5.49it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.95it/s]
127.0.0.1 - - [16/May/2024:18:50:08 +0800] "POST /infer HTTP/1.1" 200 6361 "-" "python-requests/2.31.0"
 14%|█▍        | 3/21 [00:21<02:05,  6.97s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:54,  1.81s/it]Processed prompts:   5%|▍         | 3/64 [00:01<00:31,  1.96it/s]Processed prompts:  28%|██▊       | 18/64 [00:02<00:04, 11.15it/s]Processed prompts:  70%|███████   | 45/64 [00:03<00:00, 20.66it/s]Processed prompts:  75%|███████▌  | 48/64 [00:03<00:00, 20.16it/s]Processed prompts:  80%|███████▉  | 51/64 [00:03<00:00, 20.51it/s]Processed prompts:  84%|████████▍ | 54/64 [00:03<00:00, 18.09it/s]Processed prompts:  88%|████████▊ | 56/64 [00:04<00:00, 15.90it/s]Processed prompts:  91%|█████████ | 58/64 [00:04<00:00, 10.92it/s]Processed prompts:  94%|█████████▍| 60/64 [00:05<00:00,  7.36it/s]Processed prompts:  95%|█████████▌| 61/64 [00:05<00:00,  7.02it/s]Processed prompts:  97%|█████████▋| 62/64 [00:07<00:00,  2.69it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.76it/s]
127.0.0.1 - - [16/May/2024:18:50:15 +0800] "POST /infer HTTP/1.1" 200 8669 "-" "python-requests/2.31.0"
 19%|█▉        | 4/21 [00:28<02:01,  7.12s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:54,  1.82s/it]Processed prompts:  11%|█         | 7/64 [00:02<00:12,  4.46it/s]Processed prompts:  27%|██▋       | 17/64 [00:02<00:04, 10.06it/s]Processed prompts:  78%|███████▊  | 50/64 [00:02<00:00, 38.47it/s]Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  8.97it/s]Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.54it/s]
127.0.0.1 - - [16/May/2024:18:50:22 +0800] "POST /infer HTTP/1.1" 200 4940 "-" "python-requests/2.31.0"
 24%|██▍       | 5/21 [00:35<01:51,  7.00s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:55,  1.83s/it]Processed prompts:   6%|▋         | 4/64 [00:01<00:23,  2.59it/s]Processed prompts:  34%|███▍      | 22/64 [00:02<00:02, 14.04it/s]Processed prompts:  72%|███████▏  | 46/64 [00:02<00:00, 33.60it/s]Processed prompts:  88%|████████▊ | 56/64 [00:03<00:00, 20.11it/s]Processed prompts:  98%|█████████▊| 63/64 [00:06<00:00,  8.90it/s]Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.19it/s]
127.0.0.1 - - [16/May/2024:18:50:29 +0800] "POST /infer HTTP/1.1" 200 6634 "-" "python-requests/2.31.0"
 29%|██▊       | 6/21 [00:42<01:45,  7.01s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:55,  1.83s/it]Processed prompts:  28%|██▊       | 18/64 [00:02<00:05,  8.84it/s]Processed prompts:  69%|██████▉   | 44/64 [00:03<00:01, 17.29it/s]Processed prompts:  73%|███████▎  | 47/64 [00:03<00:01, 16.78it/s]Processed prompts:  78%|███████▊  | 50/64 [00:03<00:00, 17.56it/s]Processed prompts:  84%|████████▍ | 54/64 [00:03<00:00, 18.41it/s]Processed prompts:  91%|█████████ | 58/64 [00:04<00:00, 13.70it/s]Processed prompts:  94%|█████████▍| 60/64 [00:05<00:00,  9.45it/s]Processed prompts:  97%|█████████▋| 62/64 [00:05<00:00,  8.81it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  3.81it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.87it/s]
127.0.0.1 - - [16/May/2024:18:50:36 +0800] "POST /infer HTTP/1.1" 200 7599 "-" "python-requests/2.31.0"
 33%|███▎      | 7/21 [00:49<01:39,  7.09s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:54,  1.82s/it]Processed prompts:   6%|▋         | 4/64 [00:01<00:23,  2.58it/s]Processed prompts:  30%|██▉       | 19/64 [00:02<00:03, 11.85it/s]Processed prompts:  66%|██████▌   | 42/64 [00:02<00:00, 30.70it/s]Processed prompts:  81%|████████▏ | 52/64 [00:03<00:00, 17.64it/s]Processed prompts:  92%|█████████▏| 59/64 [00:05<00:00, 11.42it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  6.82it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.98it/s]
127.0.0.1 - - [16/May/2024:18:50:43 +0800] "POST /infer HTTP/1.1" 200 8617 "-" "python-requests/2.31.0"
 38%|███▊      | 8/21 [00:56<01:32,  7.12s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:57,  1.86s/it]Processed prompts:  28%|██▊       | 18/64 [00:02<00:05,  8.88it/s]Processed prompts:  58%|█████▊    | 37/64 [00:03<00:02, 13.24it/s]Processed prompts:  61%|██████    | 39/64 [00:03<00:01, 12.82it/s]Processed prompts:  67%|██████▋   | 43/64 [00:03<00:01, 14.64it/s]Processed prompts:  72%|███████▏  | 46/64 [00:03<00:01, 15.38it/s]Processed prompts:  77%|███████▋  | 49/64 [00:04<00:00, 16.26it/s]Processed prompts:  81%|████████▏ | 52/64 [00:04<00:00, 14.95it/s]Processed prompts:  84%|████████▍ | 54/64 [00:04<00:00, 11.49it/s]Processed prompts:  89%|████████▉ | 57/64 [00:04<00:00, 11.85it/s]Processed prompts:  92%|█████████▏| 59/64 [00:05<00:00,  6.27it/s]Processed prompts:  95%|█████████▌| 61/64 [00:06<00:00,  4.09it/s]Processed prompts:  97%|█████████▋| 62/64 [00:07<00:00,  3.21it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.32it/s]
127.0.0.1 - - [16/May/2024:18:50:51 +0800] "POST /infer HTTP/1.1" 200 10856 "-" "python-requests/2.31.0"
 43%|████▎     | 9/21 [01:04<01:27,  7.32s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:58,  1.87s/it]Processed prompts:   9%|▉         | 6/64 [00:02<00:15,  3.85it/s]Processed prompts:  31%|███▏      | 20/64 [00:02<00:03, 11.92it/s]Processed prompts:  64%|██████▍   | 41/64 [00:02<00:00, 28.43it/s]Processed prompts:  78%|███████▊  | 50/64 [00:03<00:00, 17.03it/s]Processed prompts:  88%|████████▊ | 56/64 [00:04<00:00, 14.19it/s]Processed prompts:  94%|█████████▍| 60/64 [00:04<00:00, 12.84it/s]Processed prompts:  98%|█████████▊| 63/64 [00:05<00:00, 10.96it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  9.03it/s]
127.0.0.1 - - [16/May/2024:18:50:58 +0800] "POST /infer HTTP/1.1" 200 7618 "-" "python-requests/2.31.0"
 48%|████▊     | 10/21 [01:11<01:19,  7.27s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:57,  1.86s/it]Processed prompts:  25%|██▌       | 16/64 [00:02<00:05,  8.31it/s]Processed prompts:  44%|████▍     | 28/64 [00:02<00:02, 15.46it/s]Processed prompts:  66%|██████▌   | 42/64 [00:03<00:01, 15.83it/s]Processed prompts:  72%|███████▏  | 46/64 [00:03<00:01, 17.43it/s]Processed prompts:  78%|███████▊  | 50/64 [00:03<00:00, 17.87it/s]Processed prompts:  83%|████████▎ | 53/64 [00:03<00:00, 18.32it/s]Processed prompts:  88%|████████▊ | 56/64 [00:04<00:00, 12.58it/s]Processed prompts:  91%|█████████ | 58/64 [00:04<00:00, 12.72it/s]Processed prompts:  94%|█████████▍| 60/64 [00:05<00:00,  7.52it/s]Processed prompts:  97%|█████████▋| 62/64 [00:07<00:00,  3.42it/s]Processed prompts:  98%|█████████▊| 63/64 [00:07<00:00,  3.49it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.57it/s]
127.0.0.1 - - [16/May/2024:18:51:06 +0800] "POST /infer HTTP/1.1" 200 8932 "-" "python-requests/2.31.0"
 52%|█████▏    | 11/21 [01:19<01:13,  7.35s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:56,  1.85s/it]Processed prompts:   6%|▋         | 4/64 [00:01<00:22,  2.61it/s]Processed prompts:  30%|██▉       | 19/64 [00:02<00:03, 11.77it/s]Processed prompts:  61%|██████    | 39/64 [00:03<00:01, 17.25it/s]Processed prompts:  66%|██████▌   | 42/64 [00:03<00:01, 16.47it/s]Processed prompts:  80%|███████▉  | 51/64 [00:03<00:00, 22.36it/s]Processed prompts:  86%|████████▌ | 55/64 [00:03<00:00, 21.86it/s]Processed prompts:  92%|█████████▏| 59/64 [00:04<00:00, 16.42it/s]Processed prompts:  97%|█████████▋| 62/64 [00:05<00:00, 10.60it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  4.38it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.95it/s]
127.0.0.1 - - [16/May/2024:18:51:13 +0800] "POST /infer HTTP/1.1" 200 7752 "-" "python-requests/2.31.0"
 57%|█████▋    | 12/21 [01:26<01:05,  7.31s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:54,  1.82s/it]Processed prompts:   6%|▋         | 4/64 [00:02<00:23,  2.53it/s]Processed prompts:  28%|██▊       | 18/64 [00:02<00:04, 10.55it/s]Processed prompts:  66%|██████▌   | 42/64 [00:02<00:00, 29.66it/s]Processed prompts:  83%|████████▎ | 53/64 [00:03<00:00, 16.88it/s]Processed prompts:  95%|█████████▌| 61/64 [00:05<00:00,  9.56it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.64it/s]
127.0.0.1 - - [16/May/2024:18:51:20 +0800] "POST /infer HTTP/1.1" 200 8601 "-" "python-requests/2.31.0"
 62%|██████▏   | 13/21 [01:33<00:58,  7.36s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:58,  1.88s/it]Processed prompts:   8%|▊         | 5/64 [00:02<00:18,  3.18it/s]Processed prompts:  25%|██▌       | 16/64 [00:02<00:05,  9.44it/s]Processed prompts:  41%|████      | 26/64 [00:02<00:02, 16.92it/s]Processed prompts:  66%|██████▌   | 42/64 [00:03<00:01, 18.04it/s]Processed prompts:  72%|███████▏  | 46/64 [00:03<00:01, 17.61it/s]Processed prompts:  84%|████████▍ | 54/64 [00:03<00:00, 20.85it/s]Processed prompts:  91%|█████████ | 58/64 [00:04<00:00, 16.42it/s]Processed prompts:  95%|█████████▌| 61/64 [00:05<00:00,  9.70it/s]Processed prompts:  98%|█████████▊| 63/64 [00:07<00:00,  4.45it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.61it/s]
127.0.0.1 - - [16/May/2024:18:51:28 +0800] "POST /infer HTTP/1.1" 200 8410 "-" "python-requests/2.31.0"
 67%|██████▋   | 14/21 [01:41<00:51,  7.40s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:57,  1.86s/it]Processed prompts:  28%|██▊       | 18/64 [00:02<00:05,  8.88it/s]Processed prompts:  70%|███████   | 45/64 [00:02<00:00, 26.33it/s]Processed prompts:  92%|█████████▏| 59/64 [00:03<00:00, 18.23it/s]Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.38it/s]
127.0.0.1 - - [16/May/2024:18:51:35 +0800] "POST /infer HTTP/1.1" 200 5490 "-" "python-requests/2.31.0"
 71%|███████▏  | 15/21 [01:48<00:43,  7.24s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:56,  1.85s/it]Processed prompts:   9%|▉         | 6/64 [00:02<00:15,  3.70it/s]Processed prompts:  33%|███▎      | 21/64 [00:02<00:03, 11.95it/s]Processed prompts:  69%|██████▉   | 44/64 [00:03<00:01, 18.41it/s]Processed prompts:  73%|███████▎  | 47/64 [00:03<00:00, 17.65it/s]Processed prompts:  77%|███████▋  | 49/64 [00:03<00:00, 17.30it/s]Processed prompts:  83%|████████▎ | 53/64 [00:03<00:00, 19.44it/s]Processed prompts:  89%|████████▉ | 57/64 [00:04<00:00, 22.02it/s]Processed prompts:  94%|█████████▍| 60/64 [00:04<00:00, 12.80it/s]Processed prompts:  98%|█████████▊| 63/64 [00:05<00:00,  8.90it/s]Processed prompts: 100%|██████████| 64/64 [00:05<00:00, 11.73it/s]
127.0.0.1 - - [16/May/2024:18:51:40 +0800] "POST /infer HTTP/1.1" 200 6611 "-" "python-requests/2.31.0"
 76%|███████▌  | 16/21 [01:53<00:33,  6.72s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:57,  1.87s/it]Processed prompts:   5%|▍         | 3/64 [00:01<00:32,  1.89it/s]Processed prompts:  23%|██▎       | 15/64 [00:02<00:05,  8.96it/s]Processed prompts:  48%|████▊     | 31/64 [00:02<00:01, 21.35it/s]Processed prompts:  62%|██████▎   | 40/64 [00:03<00:01, 15.30it/s]Processed prompts:  70%|███████   | 45/64 [00:03<00:01, 17.26it/s]Processed prompts:  78%|███████▊  | 50/64 [00:03<00:00, 20.04it/s]Processed prompts:  86%|████████▌ | 55/64 [00:04<00:00, 16.60it/s]Processed prompts:  92%|█████████▏| 59/64 [00:04<00:00, 12.00it/s]Processed prompts:  97%|█████████▋| 62/64 [00:05<00:00, 10.47it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  4.25it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.64it/s]
127.0.0.1 - - [16/May/2024:18:51:48 +0800] "POST /infer HTTP/1.1" 200 7874 "-" "python-requests/2.31.0"
 81%|████████  | 17/21 [02:01<00:27,  6.95s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:58,  1.88s/it]Processed prompts:  28%|██▊       | 18/64 [00:02<00:05,  9.03it/s]Processed prompts:  64%|██████▍   | 41/64 [00:03<00:01, 16.06it/s]Processed prompts:  69%|██████▉   | 44/64 [00:03<00:01, 14.90it/s]Processed prompts:  77%|███████▋  | 49/64 [00:03<00:00, 17.38it/s]Processed prompts:  81%|████████▏ | 52/64 [00:03<00:00, 18.09it/s]Processed prompts:  88%|████████▊ | 56/64 [00:04<00:00, 14.57it/s]Processed prompts:  92%|█████████▏| 59/64 [00:04<00:00, 14.07it/s]Processed prompts:  95%|█████████▌| 61/64 [00:04<00:00, 13.09it/s]Processed prompts:  98%|█████████▊| 63/64 [00:05<00:00,  6.36it/s]Processed prompts: 100%|██████████| 64/64 [00:06<00:00, 10.45it/s]
127.0.0.1 - - [16/May/2024:18:51:54 +0800] "POST /infer HTTP/1.1" 200 7532 "-" "python-requests/2.31.0"
 86%|████████▌ | 18/21 [02:07<00:20,  6.72s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:57,  1.86s/it]Processed prompts:  28%|██▊       | 18/64 [00:02<00:05,  8.73it/s]Processed prompts:  55%|█████▍    | 35/64 [00:02<00:01, 19.13it/s]Processed prompts:  70%|███████   | 45/64 [00:03<00:01, 17.59it/s]Processed prompts:  80%|███████▉  | 51/64 [00:03<00:00, 17.61it/s]Processed prompts:  86%|████████▌ | 55/64 [00:03<00:00, 18.64it/s]Processed prompts:  92%|█████████▏| 59/64 [00:05<00:00,  8.97it/s]Processed prompts:  97%|█████████▋| 62/64 [00:07<00:00,  4.50it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.56it/s]
127.0.0.1 - - [16/May/2024:18:52:01 +0800] "POST /infer HTTP/1.1" 200 8866 "-" "python-requests/2.31.0"
 90%|█████████ | 19/21 [02:14<00:13,  6.96s/it]Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s]Processed prompts:   2%|▏         | 1/64 [00:01<01:56,  1.85s/it]Processed prompts:   6%|▋         | 4/64 [00:02<00:23,  2.54it/s]Processed prompts:  25%|██▌       | 16/64 [00:02<00:04,  9.70it/s]Processed prompts:  36%|███▌      | 23/64 [00:02<00:02, 14.72it/s]Processed prompts:  56%|█████▋    | 36/64 [00:02<00:01, 26.43it/s]Processed prompts:  66%|██████▌   | 42/64 [00:03<00:01, 14.65it/s]Processed prompts:  73%|███████▎  | 47/64 [00:03<00:01, 15.82it/s]Processed prompts:  80%|███████▉  | 51/64 [00:04<00:00, 17.23it/s]Processed prompts:  86%|████████▌ | 55/64 [00:04<00:00, 14.15it/s]Processed prompts:  91%|█████████ | 58/64 [00:04<00:00, 11.74it/s]Processed prompts:  94%|█████████▍| 60/64 [00:05<00:00,  8.78it/s]Processed prompts:  97%|█████████▋| 62/64 [00:06<00:00,  5.41it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  3.95it/s]Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.53it/s]
127.0.0.1 - - [16/May/2024:18:52:09 +0800] "POST /infer HTTP/1.1" 200 10012 "-" "python-requests/2.31.0"
 95%|█████████▌| 20/21 [02:22<00:07,  7.14s/it]Processed prompts:   0%|          | 0/39 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/39 [00:01<00:58,  1.55s/it]Processed prompts:  54%|█████▍    | 21/39 [00:01<00:01, 17.48it/s]Processed prompts:  85%|████████▍ | 33/39 [00:02<00:00, 13.24it/s]Processed prompts: 100%|██████████| 39/39 [00:05<00:00,  6.55it/s]
127.0.0.1 - - [16/May/2024:18:52:15 +0800] "POST /infer HTTP/1.1" 200 5096 "-" "python-requests/2.31.0"
100%|██████████| 21/21 [02:28<00:00,  6.80s/it]100%|██████████| 21/21 [02:28<00:00,  7.07s/it]
<<gsm8k_gsm8k_gen>> Gathered metrics are: defaultdict(<class 'list'>, {'accuracy': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]})
<<gsm8k_gsm8k_gen>> Final Metric is: {'accuracy': 0.034874905231235785}
For detailed output of the model, see logs/OpenBMB/MiniCPM-2B-dpo-fp32/2024-05-16_18-49-47/gsm8k_gsm8k_gen/instance.jsonl

Here are the results for each task:
|     Task      | Metric |Value |
|---------------|--------|-----:|
|gsm8k_gsm8k_gen|accuracy|0.0349|


Here are the results for each dataset:
|Dataset| Metric |Value |
|-------|--------|-----:|
|gsm8k  |accuracy|0.0349|

Path 'logs/OpenBMB/MiniCPM-2B-dpo-fp32/2024-05-16_18-49-47' already exists.

The results of all tasks have been saved to the logs/OpenBMB/MiniCPM-2B-dpo-fp32/2024-05-16_18-49-47/_all_results.json

Running time: 148.81239366531372 seconds
Running time: 148.81239366531372 seconds, the whole time: 148.8124008178711 seconds
[2024-05-16 18:52:16 +0800] [150134] [INFO] Handling signal: term
[2024-05-16 18:52:16 +0800] [150135] [INFO] Worker exiting (pid: 150135)
[2024-05-16 18:52:18 +0800] [150134] [WARNING] worker exit. pid=150135, gpus=[0]
[2024-05-16 18:52:18 +0800] [150134] [INFO] Shutting down: Master
