Running on node:
octave
CUDA version:
/var/spool/slurm/d/job123466/slurm_script: line 24: nvcc: command not found
Python version:
Python 3.11.5
nvidia_modeset       1310720  0
nvidia_uvm           1536000  0
nvidia              56705024  2 nvidia_uvm,nvidia_modeset
video                  65536  1 nvidia_modeset
drm                   614400  7 drm_kms_helper,drm_vram_helper,ast,nvidia,drm_ttm_helper,ttm
Thu May 16 13:58:06 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:61:00.0 Off |                    0 |
| N/A   27C    P0              32W / 250W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2.3.0+cu121
True
打印每个传递的参数：
../hf/OpenBMB/MiniCPM-2B-dpo-fp32
1
1
logs/OpenBMB/MiniCPM-2B-dpo-fp32
gsm8k
gen
5
Available GPUs: 1: 0
The num of datasets is: 61
Datasets for evaluation: gsm8k
The number of selected datasets is 1; the number of selected tasks is 1.
Results have been saved！
./scripts/run_job_base.sh: line 38: --dtype: command not found
[2024-05-16 13:58:16 +0800] [113567] [INFO] Starting gunicorn 22.0.0
[2024-05-16 13:58:16 +0800] [113567] [INFO] gunicorn app, gpus_num=1, workers_num=1, per_worker_gpus=1
[2024-05-16 13:58:16 +0800] [113567] [INFO] Listening at: http://127.0.0.1:5002 (113567)
[2024-05-16 13:58:16 +0800] [113567] [INFO] Using worker: sync
[2024-05-16 13:58:16 +0800] [113568] [INFO] Booting worker with pid: 113568
[2024-05-16 13:58:16 +0800] [113568] [INFO] server.age=1, worker.age=1, worker.pid=113568, gpus=[0]
INFO 05-16 13:58:20 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='../hf/OpenBMB/MiniCPM-2B-dpo-fp32', speculative_config=None, tokenizer='../hf/OpenBMB/MiniCPM-2B-dpo-fp32', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=../hf/OpenBMB/MiniCPM-2B-dpo-fp32)
INFO 05-16 13:58:21 utils.py:660] Found nccl from library /home/ltq/.config/vllm/nccl/cu12/libnccl.so.2.18.1
INFO 05-16 13:58:24 selector.py:81] Cannot use FlashAttention-2 backend because the flash_attn package is not found. Please install it for better performance.
INFO 05-16 13:58:24 selector.py:32] Using XFormers backend.
INFO 05-16 14:00:02 model_runner.py:175] Loading model weights took 5.1034 GB
INFO 05-16 14:00:03 gpu_executor.py:114] # GPU blocks: 5214, # CPU blocks: 728
INFO 05-16 14:00:05 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 05-16 14:00:05 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 05-16 14:00:10 model_runner.py:1017] Graph capturing finished in 5 secs.
model load finished
127.0.0.1 - - [16/May/2024:14:00:10 +0800] "GET /infer HTTP/1.1" 405 153 "-" "curl/7.88.1"
Service is up!
Postprocessing method: general_torch
Params file: models/model_params/vllm_sample.json
-------final CMD is------
python main.py --model general --model_args url=http://127.0.0.1:5002/infer,concurrency=1 --config_path configs/eval_config.json --output_base_path logs/OpenBMB/MiniCPM-2B-dpo-fp32 --batch_size 32 --postprocess general_torch --params models/model_params/vllm_sample.json --write_out --num_fewshot 5
-------final CMD end------
  0%|          | 0/42 [00:00<?, ?it/s]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:18,  6.41s/it]Processed prompts:   6%|▋         | 2/32 [00:07<01:33,  3.12s/it]Processed prompts:   9%|▉         | 3/32 [00:07<00:59,  2.04s/it]Processed prompts:  12%|█▎        | 4/32 [00:08<00:40,  1.44s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.76it/s]
127.0.0.1 - - [16/May/2024:14:00:21 +0800] "POST /infer HTTP/1.1" 200 26504 "-" "python-requests/2.31.0"
  2%|▏         | 1/42 [00:08<05:51,  8.57s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:20,  4.54s/it]Processed prompts:   6%|▋         | 2/32 [00:05<01:17,  2.57s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:13,  2.55s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.88it/s]
127.0.0.1 - - [16/May/2024:14:00:29 +0800] "POST /infer HTTP/1.1" 200 24520 "-" "python-requests/2.31.0"
  5%|▍         | 2/42 [00:16<05:36,  8.41s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:02<01:27,  2.82s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:14,  4.50s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.77it/s]
127.0.0.1 - - [16/May/2024:14:00:37 +0800] "POST /infer HTTP/1.1" 200 24558 "-" "python-requests/2.31.0"
  7%|▋         | 3/42 [00:25<05:30,  8.48s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:28,  8.66s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.70it/s]
127.0.0.1 - - [16/May/2024:14:00:46 +0800] "POST /infer HTTP/1.1" 200 26662 "-" "python-requests/2.31.0"
 10%|▉         | 4/42 [00:34<05:25,  8.57s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<02:00,  3.88s/it]Processed prompts:   6%|▋         | 2/32 [00:04<01:03,  2.12s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:19,  2.74s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.88it/s]
127.0.0.1 - - [16/May/2024:14:00:54 +0800] "POST /infer HTTP/1.1" 200 24164 "-" "python-requests/2.31.0"
 12%|█▏        | 5/42 [00:42<05:13,  8.48s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:24,  4.66s/it]Processed prompts:   6%|▋         | 2/32 [00:08<01:56,  3.90s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:04,  2.23s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.87it/s]
127.0.0.1 - - [16/May/2024:14:01:03 +0800] "POST /infer HTTP/1.1" 200 24881 "-" "python-requests/2.31.0"
 14%|█▍        | 6/42 [00:50<05:03,  8.42s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<02:01,  3.93s/it]Processed prompts:   6%|▋         | 2/32 [00:07<01:44,  3.48s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:09,  2.41s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.89it/s]
127.0.0.1 - - [16/May/2024:14:01:11 +0800] "POST /infer HTTP/1.1" 200 24986 "-" "python-requests/2.31.0"
 17%|█▋        | 7/42 [00:59<04:53,  8.38s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:41,  5.21s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:00,  4.02s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.81it/s]
127.0.0.1 - - [16/May/2024:14:01:20 +0800] "POST /infer HTTP/1.1" 200 24738 "-" "python-requests/2.31.0"
 19%|█▉        | 8/42 [01:07<04:45,  8.40s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:49,  3.55s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:02,  4.08s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  4.00it/s]
127.0.0.1 - - [16/May/2024:14:01:28 +0800] "POST /infer HTTP/1.1" 200 23955 "-" "python-requests/2.31.0"
 21%|██▏       | 9/42 [01:15<04:33,  8.29s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:09,  4.18s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:07,  4.26s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.76it/s]
127.0.0.1 - - [16/May/2024:14:01:36 +0800] "POST /infer HTTP/1.1" 200 24765 "-" "python-requests/2.31.0"
 24%|██▍       | 10/42 [01:24<04:27,  8.37s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:02<01:05,  2.12s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:17,  4.57s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.81it/s]
127.0.0.1 - - [16/May/2024:14:01:45 +0800] "POST /infer HTTP/1.1" 200 24502 "-" "python-requests/2.31.0"
 26%|██▌       | 11/42 [01:32<04:20,  8.40s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:16,  4.41s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:01,  4.05s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.90it/s]
127.0.0.1 - - [16/May/2024:14:01:53 +0800] "POST /infer HTTP/1.1" 200 24881 "-" "python-requests/2.31.0"
 29%|██▊       | 12/42 [01:40<04:10,  8.36s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:41,  3.28s/it]Processed prompts:   6%|▋         | 2/32 [00:03<00:49,  1.65s/it]Processed prompts:   9%|▉         | 3/32 [00:04<00:31,  1.10s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:32,  1.15s/it]Processed prompts:  16%|█▌        | 5/32 [00:07<00:43,  1.61s/it]Processed prompts: 100%|██████████| 32/32 [00:07<00:00,  4.06it/s]
127.0.0.1 - - [16/May/2024:14:02:01 +0800] "POST /infer HTTP/1.1" 200 23203 "-" "python-requests/2.31.0"
 31%|███       | 13/42 [01:48<03:58,  8.23s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:48,  5.43s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:04,  4.16s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.67it/s]
127.0.0.1 - - [16/May/2024:14:02:10 +0800] "POST /infer HTTP/1.1" 200 25056 "-" "python-requests/2.31.0"
 33%|███▎      | 14/42 [01:57<03:56,  8.44s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:50,  3.57s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:08,  4.30s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.82it/s]
127.0.0.1 - - [16/May/2024:14:02:18 +0800] "POST /infer HTTP/1.1" 200 25317 "-" "python-requests/2.31.0"
 36%|███▌      | 15/42 [02:06<03:47,  8.43s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:18,  4.48s/it]Processed prompts:   9%|▉         | 3/32 [00:06<00:53,  1.83s/it]Processed prompts:  12%|█▎        | 4/32 [00:08<00:53,  1.90s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.84it/s]
127.0.0.1 - - [16/May/2024:14:02:27 +0800] "POST /infer HTTP/1.1" 200 25388 "-" "python-requests/2.31.0"
 38%|███▊      | 16/42 [02:14<03:38,  8.42s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:29,  8.70s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.68it/s]
127.0.0.1 - - [16/May/2024:14:02:35 +0800] "POST /infer HTTP/1.1" 200 25658 "-" "python-requests/2.31.0"
 40%|████      | 17/42 [02:23<03:32,  8.52s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:06,  4.07s/it]Processed prompts:   6%|▋         | 2/32 [00:05<01:15,  2.51s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:17,  2.66s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.84it/s]
127.0.0.1 - - [16/May/2024:14:02:44 +0800] "POST /infer HTTP/1.1" 200 24813 "-" "python-requests/2.31.0"
 43%|████▎     | 18/42 [02:31<03:23,  8.48s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:01<00:55,  1.80s/it]Processed prompts:   6%|▋         | 2/32 [00:03<00:50,  1.68s/it]Processed prompts:   9%|▉         | 3/32 [00:04<00:34,  1.20s/it]Processed prompts:  12%|█▎        | 4/32 [00:05<00:32,  1.15s/it]Processed prompts:  16%|█▌        | 5/32 [00:05<00:25,  1.08it/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:39,  1.52s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.85it/s]
127.0.0.1 - - [16/May/2024:14:02:52 +0800] "POST /infer HTTP/1.1" 200 21792 "-" "python-requests/2.31.0"
 45%|████▌     | 19/42 [02:40<03:14,  8.45s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:30,  4.86s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:04,  4.14s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.77it/s]
127.0.0.1 - - [16/May/2024:14:03:01 +0800] "POST /infer HTTP/1.1" 200 24339 "-" "python-requests/2.31.0"
 48%|████▊     | 20/42 [02:48<03:06,  8.48s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:02<01:24,  2.72s/it]Processed prompts:   6%|▋         | 2/32 [00:03<00:49,  1.65s/it]Processed prompts:   9%|▉         | 3/32 [00:06<01:01,  2.12s/it]Processed prompts:  12%|█▎        | 4/32 [00:06<00:41,  1.47s/it]Processed prompts:  16%|█▌        | 5/32 [00:08<00:39,  1.46s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.84it/s]
127.0.0.1 - - [16/May/2024:14:03:09 +0800] "POST /infer HTTP/1.1" 200 23641 "-" "python-requests/2.31.0"
 50%|█████     | 21/42 [02:56<02:57,  8.45s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:05<03:05,  5.98s/it]Processed prompts:   6%|▋         | 2/32 [00:06<01:18,  2.61s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:10,  2.42s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.79it/s]
127.0.0.1 - - [16/May/2024:14:03:17 +0800] "POST /infer HTTP/1.1" 200 24198 "-" "python-requests/2.31.0"
 52%|█████▏    | 22/42 [03:05<02:49,  8.46s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:16,  4.41s/it]Processed prompts:   9%|▉         | 3/32 [00:06<00:54,  1.88s/it]Processed prompts:  12%|█▎        | 4/32 [00:08<00:53,  1.91s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.82it/s]
127.0.0.1 - - [16/May/2024:14:03:26 +0800] "POST /infer HTTP/1.1" 200 23814 "-" "python-requests/2.31.0"
 55%|█████▍    | 23/42 [03:13<02:40,  8.45s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:05,  4.05s/it]Processed prompts:   6%|▋         | 2/32 [00:06<01:39,  3.31s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:15,  2.59s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.73it/s]
127.0.0.1 - - [16/May/2024:14:03:35 +0800] "POST /infer HTTP/1.1" 200 25539 "-" "python-requests/2.31.0"
 57%|█████▋    | 24/42 [03:22<02:33,  8.50s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:02<01:32,  2.98s/it]Processed prompts:   6%|▋         | 2/32 [00:05<01:14,  2.49s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:49,  1.70s/it]Processed prompts:  16%|█▌        | 5/32 [00:06<00:22,  1.19it/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:29,  1.14s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.93it/s]
127.0.0.1 - - [16/May/2024:14:03:43 +0800] "POST /infer HTTP/1.1" 200 23281 "-" "python-requests/2.31.0"
 60%|█████▉    | 25/42 [03:30<02:22,  8.41s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:20,  8.39s/it]Processed prompts:   6%|▋         | 2/32 [00:08<01:46,  3.55s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.74it/s]
127.0.0.1 - - [16/May/2024:14:03:51 +0800] "POST /infer HTTP/1.1" 200 25178 "-" "python-requests/2.31.0"
 62%|██████▏   | 26/42 [03:39<02:15,  8.47s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:52,  3.63s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:12,  4.41s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.73it/s]
127.0.0.1 - - [16/May/2024:14:04:00 +0800] "POST /infer HTTP/1.1" 200 25705 "-" "python-requests/2.31.0"
 64%|██████▍   | 27/42 [03:47<02:07,  8.52s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:11,  6.18s/it]Processed prompts:   6%|▋         | 2/32 [00:06<01:22,  2.74s/it]Processed prompts:   9%|▉         | 3/32 [00:07<00:56,  1.94s/it]Processed prompts:  12%|█▎        | 4/32 [00:08<00:42,  1.53s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.81it/s]
127.0.0.1 - - [16/May/2024:14:04:08 +0800] "POST /infer HTTP/1.1" 200 25179 "-" "python-requests/2.31.0"
 67%|██████▋   | 28/42 [03:56<01:58,  8.50s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:07<04:04,  7.88s/it]Processed prompts:   6%|▋         | 2/32 [00:08<01:50,  3.69s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.71it/s]
127.0.0.1 - - [16/May/2024:14:04:17 +0800] "POST /infer HTTP/1.1" 200 26219 "-" "python-requests/2.31.0"
 69%|██████▉   | 29/42 [04:05<01:51,  8.55s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<02:02,  3.94s/it]Processed prompts:   9%|▉         | 3/32 [00:04<00:40,  1.41s/it]Processed prompts:  12%|█▎        | 4/32 [00:08<00:59,  2.13s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.77it/s]
127.0.0.1 - - [16/May/2024:14:04:26 +0800] "POST /infer HTTP/1.1" 200 23297 "-" "python-requests/2.31.0"
 71%|███████▏  | 30/42 [04:13<01:42,  8.55s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:23,  8.52s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.76it/s]
127.0.0.1 - - [16/May/2024:14:04:34 +0800] "POST /infer HTTP/1.1" 200 25420 "-" "python-requests/2.31.0"
 74%|███████▍  | 31/42 [04:22<01:34,  8.60s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:19,  4.49s/it]Processed prompts:   6%|▋         | 2/32 [00:06<01:25,  2.86s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:14,  2.57s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.80it/s]
127.0.0.1 - - [16/May/2024:14:04:43 +0800] "POST /infer HTTP/1.1" 200 24737 "-" "python-requests/2.31.0"
 76%|███████▌  | 32/42 [04:30<01:25,  8.56s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<01:40,  3.23s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:08,  4.27s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.89it/s]
127.0.0.1 - - [16/May/2024:14:04:51 +0800] "POST /infer HTTP/1.1" 200 24641 "-" "python-requests/2.31.0"
 79%|███████▊  | 33/42 [04:39<01:16,  8.48s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:27,  8.64s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.70it/s]
127.0.0.1 - - [16/May/2024:14:05:00 +0800] "POST /infer HTTP/1.1" 200 25578 "-" "python-requests/2.31.0"
 81%|████████  | 34/42 [04:47<01:08,  8.55s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:53,  5.61s/it]Processed prompts:   6%|▋         | 2/32 [00:08<01:58,  3.96s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.80it/s]
127.0.0.1 - - [16/May/2024:14:05:08 +0800] "POST /infer HTTP/1.1" 200 26134 "-" "python-requests/2.31.0"
 83%|████████▎ | 35/42 [04:56<00:59,  8.52s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:03<02:00,  3.90s/it]Processed prompts:   6%|▋         | 2/32 [00:08<02:09,  4.33s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.75it/s]
127.0.0.1 - - [16/May/2024:14:05:17 +0800] "POST /infer HTTP/1.1" 200 24769 "-" "python-requests/2.31.0"
 86%|████████▌ | 36/42 [05:04<00:51,  8.54s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:13,  8.17s/it]Processed prompts:   6%|▋         | 2/32 [00:08<01:49,  3.66s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.69it/s]
127.0.0.1 - - [16/May/2024:14:05:26 +0800] "POST /infer HTTP/1.1" 200 25742 "-" "python-requests/2.31.0"
 88%|████████▊ | 37/42 [05:13<00:42,  8.60s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:22,  8.47s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.78it/s]
127.0.0.1 - - [16/May/2024:14:05:34 +0800] "POST /infer HTTP/1.1" 200 26106 "-" "python-requests/2.31.0"
 90%|█████████ | 38/42 [05:22<00:34,  8.57s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:02<01:18,  2.53s/it]Processed prompts:   6%|▋         | 2/32 [00:04<01:09,  2.31s/it]Processed prompts:   9%|▉         | 3/32 [00:06<00:59,  2.07s/it]Processed prompts:  12%|█▎        | 4/32 [00:07<00:42,  1.51s/it]Processed prompts:  16%|█▌        | 5/32 [00:07<00:28,  1.07s/it]Processed prompts:  19%|█▉        | 6/32 [00:08<00:25,  1.04it/s]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.92it/s]
127.0.0.1 - - [16/May/2024:14:05:42 +0800] "POST /infer HTTP/1.1" 200 23350 "-" "python-requests/2.31.0"
 93%|█████████▎| 39/42 [05:30<00:25,  8.47s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:45,  5.34s/it]Processed prompts:   6%|▋         | 2/32 [00:06<01:33,  3.13s/it]Processed prompts:   9%|▉         | 3/32 [00:08<01:09,  2.40s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.78it/s]
127.0.0.1 - - [16/May/2024:14:05:51 +0800] "POST /infer HTTP/1.1" 200 25378 "-" "python-requests/2.31.0"
 95%|█████████▌| 40/42 [05:38<00:16,  8.48s/it]Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:07,  4.10s/it]Processed prompts:   6%|▋         | 2/32 [00:04<00:54,  1.83s/it]Processed prompts:   9%|▉         | 3/32 [00:05<00:47,  1.65s/it]Processed prompts:  12%|█▎        | 4/32 [00:07<00:43,  1.55s/it]Processed prompts:  16%|█▌        | 5/32 [00:08<00:39,  1.45s/it]Processed prompts: 100%|██████████| 32/32 [00:08<00:00,  3.79it/s]
127.0.0.1 - - [16/May/2024:14:05:59 +0800] "POST /infer HTTP/1.1" 200 24252 "-" "python-requests/2.31.0"
 98%|█████████▊| 41/42 [05:47<00:08,  8.49s/it]Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s]Processed prompts:  14%|█▍        | 1/7 [00:01<00:09,  1.61s/it]Processed prompts:  29%|██▊       | 2/7 [00:03<00:09,  1.94s/it]Processed prompts: 100%|██████████| 7/7 [00:03<00:00,  1.85it/s]
127.0.0.1 - - [16/May/2024:14:06:03 +0800] "POST /infer HTTP/1.1" 200 4881 "-" "python-requests/2.31.0"
100%|██████████| 42/42 [05:51<00:00,  7.08s/it]100%|██████████| 42/42 [05:51<00:00,  8.36s/it]
<<gsm8k_gsm8k_gen>> Gathered metrics are: defaultdict(<class 'list'>, {'accuracy': [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]})
<<gsm8k_gsm8k_gen>> Final Metric is: {'accuracy': 0.43442001516300227}
For detailed output of the model, see logs/OpenBMB/MiniCPM-2B-dpo-fp32/2024-05-16_14-00-12/gsm8k_gsm8k_gen/instance.jsonl

Here are the results for each task:
|     Task      | Metric |Value |
|---------------|--------|-----:|
|gsm8k_gsm8k_gen|accuracy|0.4344|


Here are the results for each dataset:
|Dataset| Metric |Value |
|-------|--------|-----:|
|gsm8k  |accuracy|0.4344|

Path 'logs/OpenBMB/MiniCPM-2B-dpo-fp32/2024-05-16_14-00-12' already exists.

The results of all tasks have been saved to the logs/OpenBMB/MiniCPM-2B-dpo-fp32/2024-05-16_14-00-12/_all_results.json

Running time: 351.56780433654785 seconds
Running time: 351.56780433654785 seconds, the whole time: 351.56780791282654 seconds
[2024-05-16 14:06:04 +0800] [113567] [INFO] Handling signal: term
[2024-05-16 14:06:04 +0800] [113568] [INFO] Worker exiting (pid: 113568)
[2024-05-16 14:06:06 +0800] [113567] [WARNING] worker exit. pid=113568, gpus=[0]
[2024-05-16 14:06:06 +0800] [113567] [INFO] Shutting down: Master
